{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "from mlxtend.frequent_patterns import apriori, association_rules, fpgrowth\n",
    "from mlxtend.preprocessing import TransactionEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_meal_and_no_meal_instances(cgm_data_file, insulin_data_file):\n",
    "    if \".xls\" in cgm_data_file:\n",
    "        cgm_df = pd.read_excel(cgm_data_file, parse_dates=[['Date', 'Time']])\n",
    "    elif \".csv\" in cgm_data_file:\n",
    "        cgm_df = pd.read_csv(cgm_data_file, parse_dates=[\n",
    "                             ['Date', 'Time']], low_memory=False)\n",
    "\n",
    "    if \".xls\" in insulin_data_file:\n",
    "        insulin_df = pd.read_excel(\n",
    "            insulin_data_file, parse_dates=[['Date', 'Time']])\n",
    "    elif \".csv\" in insulin_data_file:\n",
    "        insulin_df = pd.read_csv(insulin_data_file, parse_dates=[\n",
    "                                 ['Date', 'Time']], low_memory=False)\n",
    "\n",
    "    # Filter only the needed fields to cp_df dataframe\n",
    "    cp_df = cgm_df[['Date_Time', 'Sensor Glucose (mg/dL)']]\n",
    "    cp_df = cp_df.set_index(['Date_Time'])\n",
    "    cp_df.sort_index(inplace=True)\n",
    "\n",
    "    # Filter only the needed fields to cp_ins_df dataframe\n",
    "    cp_ins_df = insulin_df[['Date_Time', 'BWZ Estimate (U)', 'BWZ Carb Input (grams)']]\n",
    "\n",
    "    # extract rows with Carb/meal intake values > 0\n",
    "    meal_intake_rows = cp_ins_df.loc[cp_ins_df['BWZ Carb Input (grams)'] > 0, [\n",
    "        'Date_Time', 'BWZ Estimate (U)', 'BWZ Carb Input (grams)']]\n",
    "    meal_intake_rows.sort_values(['Date_Time'], inplace=True)\n",
    "    meal_intake_rows.reset_index(inplace=True)\n",
    "    meal_intake_rows.drop('index', inplace=True, axis=1)\n",
    "    \n",
    "    valid_meal_data_times = meal_intake_rows\n",
    "\n",
    "    rows_to_drop = []\n",
    "    last_date = valid_meal_data_times['Date_Time'][0]-timedelta(hours=10)\n",
    "\n",
    "    for ind, row in valid_meal_data_times.iterrows():\n",
    "        if row['Date_Time'] < (last_date+timedelta(hours=4)):\n",
    "            rows_to_drop.append(ind-1)\n",
    "        last_date = row['Date_Time']\n",
    "\n",
    "    valid_meal_data_times.drop(rows_to_drop, inplace=True)\n",
    "    valid_meal_data_times.reset_index(inplace=True)\n",
    "\n",
    "    # Extract Meal and No_meal window data\n",
    "    meal_data = pd.DataFrame()\n",
    "    no_meal_data = pd.DataFrame()\n",
    "\n",
    "    for ind, row in valid_meal_data_times.iterrows():\n",
    "        # meal_time window data\n",
    "        m_data = cp_df[row['Date_Time'] -\n",
    "                       timedelta(minutes=30):row['Date_Time']+timedelta(hours=2)]\n",
    "        # no_meal_time window data\n",
    "        n_m_data = cp_df[row['Date_Time'] +\n",
    "                         timedelta(hours=2):row['Date_Time']+timedelta(hours=4)]\n",
    "\n",
    "        m_data.reset_index(inplace=True)\n",
    "        n_m_data.reset_index(inplace=True)\n",
    "\n",
    "        # Avoid meal and no_meal data instances with less than 30 and 24 observations respectively on a particular time window\n",
    "        # Avoid instances with more than 5 NaN values\n",
    "        # if (len(m_data) >= 30) and (m_data['Sensor Glucose (mg/dL)'][:30].isna().sum() <= 28):\n",
    "        if (len(m_data) >= 30):\n",
    "            m_data = m_data['Sensor Glucose (mg/dL)'][:30]\n",
    "            m_data.at[30] = round(row['BWZ Estimate (U)']) # Insulin Bolus Data\n",
    "            meal_data = pd.concat(\n",
    "                [meal_data, m_data], ignore_index=True, axis=1)\n",
    "\n",
    "        if (len(n_m_data) >= 24) and (n_m_data['Sensor Glucose (mg/dL)'][:24].isna().sum() <= 5):\n",
    "        # if (len(n_m_data) >= 24):\n",
    "            no_meal_data = pd.concat(\n",
    "                [no_meal_data, n_m_data['Sensor Glucose (mg/dL)'][:24]], ignore_index=True, axis=1)\n",
    "\n",
    "    meal_data = meal_data.transpose()\n",
    "    no_meal_data = no_meal_data.transpose()\n",
    "\n",
    "    return [meal_data, no_meal_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_transactions(data_matrix, cgm_min):\n",
    "    columns = [\"b_max\", \"b_meal\", \"insulin_bolus\"]\n",
    "    transaction_matrix = pd.DataFrame(columns=columns)\n",
    "\n",
    "    for ind, data in data_matrix.iterrows():\n",
    "        ins_bol = data.iloc[30]\n",
    "        data.drop([30], inplace=True)\n",
    "        max_cgm_of_meal = data.max()\n",
    "        cgm_at_time_of_meal = data.iloc[10]\n",
    "\n",
    "        if not (np.isnan([max_cgm_of_meal, cgm_at_time_of_meal, ins_bol]).any()):\n",
    "            transaction = [int((max_cgm_of_meal-cgm_min)/20), int((cgm_at_time_of_meal-cgm_min)/20), int(ins_bol)]\n",
    "            transaction_matrix.loc[ind] = [\"{}_{}\".format(x, y) for x, y in zip(columns, transaction)]\n",
    "            # transaction_matrix.loc[ind] = transaction\n",
    "\n",
    "        # NOTE: There are some NaNs in cgm_at_time_of_meal values\n",
    "\n",
    "    return transaction_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENTRY POINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entry Point\n",
    "\n",
    "#FROMAT: [cgm_data, insulin_data]\n",
    "# training_input_files = [[\"data/CGMData.csv\", \"data/InsulinData.csv\"]]\n",
    "                        # [\"data/CGMData670GPatient3.csv\", \"data/InsulinAndMealIntake670GPatient3.csv\"]]\n",
    "\n",
    "# meal_train_data_matrix_1, no_meal_train_data_matrix_1 = extract_meal_and_no_meal_instances(\n",
    "#     training_input_files[0][0], training_input_files[0][1])\n",
    "# meal_train_data_matrix_2, no_meal_train_data_matrix_2 = extract_meal_and_no_meal_instances(\n",
    "#     training_input_files[1][0], training_input_files[1][1])\n",
    "\n",
    "\n",
    "# training_input_files = [\n",
    "#     [\"CGMData.csv\", \"InsulinData.csv\"]]\n",
    "training_input_files = [\n",
    "    [\"data/CGMData.csv\", \"data/InsulinData.csv\"]]\n",
    "    # [\"data/CGMData670GPatient3.csv\", \"data/InsulinAndMealIntake670GPatient3.csv\"]]\n",
    "\n",
    "meal_train_data_matrix_1, no_meal_train_data_matrix_1 = extract_meal_and_no_meal_instances(\n",
    "    training_input_files[0][0], training_input_files[0][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgm_max = meal_train_data_matrix_1.max().max()\n",
    "cgm_min = meal_train_data_matrix_1.min().min()\n",
    "\n",
    "n_bins = ceil((cgm_max-cgm_min)/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = extract_transactions(meal_train_data_matrix_1, cgm_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = set()\n",
    "for col in transactions:\n",
    "    items.update(transactions[col].unique())\n",
    "itemset = set(items)\n",
    "encoded_vals = []\n",
    "for index, row in transactions.iterrows():\n",
    "    rowset = set(row) \n",
    "    labels = {}\n",
    "    uncommons = list(itemset - rowset)\n",
    "    commons = list(itemset.intersection(rowset))\n",
    "    for uc in uncommons:\n",
    "        labels[uc] = 0\n",
    "    for com in commons:\n",
    "        labels[com] = 1\n",
    "    encoded_vals.append(labels)\n",
    "encoded_vals[0]\n",
    "ohe_df = pd.DataFrame(encoded_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(372, 48)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use TransactionEncoder for OneHotEncoding\n",
    "# te = TransactionEncoder()\n",
    "# te_array = te.fit(transactions.values).transform(transactions.values)\n",
    "# te_df = pd.DataFrame(te_array, columns=te.columns_)\n",
    "\n",
    "# # Use fpgrowth for frequent itemsets.\n",
    "# fp_freq_items = fpgrowth(ohe_df, min_support=0.005, use_colnames=True)\n",
    "# fp_freq_items['length'] = fp_freq_items['itemsets'].apply(lambda x: len(x))\n",
    "# fp_freq_items_3 = fp_freq_items[(fp_freq_items['length']==3)]\n",
    "# fp_freq_items_3.sort_values(['support'], inplace=True, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2196 combinations | Sampling itemset size 4\n"
     ]
    }
   ],
   "source": [
    "freq_items = apriori(ohe_df, min_support=0.004, use_colnames=True, verbose=1)\n",
    "freq_items['length'] = freq_items['itemsets'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_items_3 = freq_items[(freq_items['length']==3)]\n",
    "freq_items_3.sort_values(['support'], inplace=True, ascending=False)\n",
    "max_support = freq_items_3['support'].max()\n",
    "most_freq_itemset_3 = freq_items_3[(freq_items_3['support']==max_support)] # Export to 1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = association_rules(freq_items, metric=\"confidence\", min_threshold=0.0004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add columns with antecedent length and rule of form \"{Bmax, Bmeal} -> Ib\"\n",
    "rules[\"antecedent_len\"] = rules[\"antecedents\"].apply(lambda x: len(x))\n",
    "rules[\"is_rule_form\"] = rules[\"antecedents\"].apply(lambda x: all([(((\"b_meal\" in str(i)) or (\"b_max\" in str(i))) and (\"insulin\" not in str(i))) for i in list(x)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_of_form = rules[(rules[\"is_rule_form\"]) & (rules[\"antecedent_len\"] == 2)]\n",
    "# rules_of_form = rules[(rules[\"antecedent_len\"] == 2)]\n",
    "rules_of_form.sort_values(['confidence'], inplace=True, ascending=False)\n",
    "max_confidence = rules_of_form['confidence'].max()\n",
    "\n",
    "max_conf_rules = rules_of_form[(rules_of_form['confidence']==max_confidence)]   # Export to 2.csv\n",
    "least_conf_rules = rules_of_form[(rules_of_form['confidence']<=0.15)]   # Export to 3.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_h/28b052cn31b8vhcwl4dtj9kc0000gn/T/ipykernel_43061/801274636.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  most_freq_itemset_3['output'] = \"\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "most_freq_itemset_3['output'] = \"\"\n",
    "\n",
    "for ind, row in most_freq_itemset_3.iterrows():\n",
    "    res_list = [0,0,0]  #[b_max, b_meal, insulin_bolus]\n",
    "    for ele in row['itemsets']:\n",
    "        match = re.match(r\"\\D+(\\d+)\", ele)\n",
    "        if \"b_max\" in ele:\n",
    "            res_list[0] = match.group(1)\n",
    "        elif \"b_meal\" in ele:\n",
    "            res_list[1] = match.group(1)\n",
    "        elif \"insulin\" in ele:\n",
    "            res_list[2] = match.group(1)\n",
    "    out_str = \", \".join(res_list)\n",
    "    most_freq_itemset_3.loc[ind, 'output'] = \"(\" + out_str + \")\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_rule_output(df):\n",
    "\n",
    "    df['output'] = \"\"\n",
    "\n",
    "    for ind, row in df.iterrows():\n",
    "        res_list = [0,0,0]  #[b_max, b_meal, insulin_bolus]\n",
    "        for ele in (list(row['antecedents']) + list(row['consequents'])):\n",
    "            match = re.match(r\"\\D+(\\d+)\", ele)\n",
    "            if \"b_max\" in ele:\n",
    "                res_list[0] = match.group(1)\n",
    "            elif \"b_meal\" in ele:\n",
    "                res_list[1] = match.group(1)\n",
    "            elif \"insulin\" in ele:\n",
    "                res_list[2] = match.group(1)\n",
    "        ant = \"{}, {}\".format(res_list[0], res_list[1])\n",
    "        cons = \"{}\".format(res_list[2])\n",
    "        out_str = \"{\" + ant + \"} ->\" + cons\n",
    "        df.loc[ind, 'output'] = out_str\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_h/28b052cn31b8vhcwl4dtj9kc0000gn/T/ipykernel_43061/980403513.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['output'] = \"\"\n"
     ]
    }
   ],
   "source": [
    "set_rule_output(max_conf_rules)\n",
    "set_rule_output(least_conf_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_of_form.to_csv(\"rules.csv\", index=False, header=False)\n",
    "most_freq_itemset_3['output'].to_csv(\"1.csv\", index=False, header=False)\n",
    "max_conf_rules['output'].to_csv(\"2.csv\", index=False, header=False)\n",
    "least_conf_rules['output'].to_csv(\"3.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_items_3.to_csv(\"frq_its.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ef8d5e935b24b0631058493e758f9731e9054e35b0ddb1f024466022840975ee"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
